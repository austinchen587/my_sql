# tool/views/views_chat.py

import json
import logging
import re
import traceback
from collections import Counter
from datetime import datetime
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods
from django.db import connection
from django.conf import settings
from django.shortcuts import render

logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨æ•°æ®åº“ç»“æ„è®¤çŸ¥çŠ¶æ€
database_understanding_cache = {
    'last_updated': None,
    'schema_info': None,
    'sample_data': None
}

class ChatMessageProcessor:
    """èŠå¤©æ¶ˆæ¯å¤„ç†å™¨ - å¤„ç†å‰ç«¯å‘é€çš„æ‰€æœ‰æ¶ˆæ¯"""
    
    def __init__(self):
        self.ai_client = None
        self.setup_ai_client()
        # å­˜å‚¨ç”¨æˆ·ä¼šè¯çŠ¶æ€
        self.user_sessions = {}

    def setup_ai_client(self):
        """è®¾ç½®AIå®¢æˆ·ç«¯ - å¢å¼ºé”™è¯¯å¤„ç†"""
        try:
            # æ£€æŸ¥é…ç½®æ˜¯å¦å­˜åœ¨
            if not hasattr(settings, 'AI_API_KEY') or not settings.AI_API_KEY or settings.AI_API_KEY == 'your-siliconflow-apikey':
                logger.warning("AI_API_KEYæœªæ­£ç¡®é…ç½®ï¼Œå°†ä½¿ç”¨æœ¬åœ°SQLç”Ÿæˆ")
                return
            
            # å°è¯•å¯¼å…¥openaiåº“
            try:
                import openai
            except ImportError:
                logger.warning("openaiåº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æœ¬åœ°SQLç”Ÿæˆ")
                return
            
            # è·å–é…ç½®
            api_base = getattr(settings, 'AI_API_BASE', 'https://api.siliconflow.cn/v1')
            api_key = settings.AI_API_KEY
            model_name = getattr(settings, 'AI_MODEL', 'deepseek-ai/DeepSeek-V3.1-Terminus')
            
            logger.info(f"åˆå§‹åŒ–AIå®¢æˆ·ç«¯ï¼ŒAPI Base: {api_base}, Model: {model_name}")
            
            self.ai_client = openai.OpenAI(
                api_key=api_key,
                base_url=api_base
            )
            
            # ä¿å­˜æ¨¡å‹åç§°ä¾›åç»­ä½¿ç”¨
            self.model_name = model_name
            
            # æµ‹è¯•è¿æ¥
            if self.test_ai_connection():
                logger.info("AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("AIå®¢æˆ·ç«¯è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œå°†ä½¿ç”¨æœ¬åœ°SQLç”Ÿæˆ")
                self.ai_client = None
                
        except Exception as e:
            logger.error(f"AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.ai_client = None

    def test_ai_connection(self):
        """æµ‹è¯•AIè¿æ¥"""
        try:
            if not self.ai_client:
                return False
                
            # ç®€å•çš„è¿æ¥æµ‹è¯•
            self.ai_client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": "æµ‹è¯•"}],
                max_tokens=10
            )
            return True
        except Exception as e:
            logger.error(f"AIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False

    def process_message(self, request_data):
        """å¤„ç†æ¶ˆæ¯è·¯ç”± - ç»Ÿä¸€å“åº”æ ¼å¼"""
        try:
            message = request_data.get('message', '').strip()
            message_type = request_data.get('message_type', 'normal_chat')
            session_id = request_data.get('session_id', 'default')
            
            logger.info(f"æ”¶åˆ°æ¶ˆæ¯: {message[:100]}, ç±»å‹: {message_type}, ä¼šè¯: {session_id}")
            
            # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
            if session_id not in self.user_sessions:
                self.user_sessions[session_id] = {
                    'psql_used': False,
                    'query_count': 0,
                    'last_query_time': None,
                    'database_understood': False,
                    'conversation_history': []
                }
            
            # è®°å½•å¯¹è¯å†å²
            self.user_sessions[session_id]['conversation_history'].append({
                'role': 'user',
                'content': message,
                'timestamp': datetime.now().isoformat()
            })
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«#psqlæ ‡è®°
            has_psql_marker = (
                message_type == 'data_analysis' or 
                '#psql' in message.lower() or 
                '#p s q l' in message.lower()
            )
            
            if has_psql_marker:
                # æ ‡è®°ç”¨æˆ·å·²ä½¿ç”¨è¿‡psql
                self.user_sessions[session_id]['psql_used'] = True
                self.user_sessions[session_id]['query_count'] += 1
                self.user_sessions[session_id]['last_query_time'] = datetime.now()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ•°æ®åº“è®¤çŸ¥æµç¨‹
                needs_database_intro = self.check_if_needs_database_intro(message, session_id)
                if needs_database_intro:
                    response_data = self.handle_database_introduction(message, session_id)
                else:
                    response_data = self.handle_intelligent_data_analysis(message, session_id)
            else:
                response_data = self.handle_normal_chat(message)
            
            # è®°å½•åŠ©æ‰‹å“åº”
            if response_data.get('status') == 'success':
                self.user_sessions[session_id]['conversation_history'].append({
                    'role': 'assistant',
                    'content': response_data.get('message', ''),
                    'timestamp': datetime.now().isoformat()
                })
            
            # ç¡®ä¿å“åº”æ ¼å¼ç»Ÿä¸€
            return self.ensure_response_format(response_data)
            
        except Exception as e:
            logger.error(f"æ¶ˆæ¯å¤„ç†å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return self.error_response(f"å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

    def check_if_needs_database_intro(self, message, session_id):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ•°æ®åº“ä»‹ç»æµç¨‹"""
        session = self.user_sessions.get(session_id, {})
        
        # å¦‚æœæ•°æ®åº“å·²ç»ç†è§£è¿‡ï¼Œç›´æ¥è¿›å…¥æ•°æ®åˆ†æ
        if session.get('database_understood', False):
            return False
        
        # æ¸…ç†æ¶ˆæ¯ï¼Œåªçœ‹æ ¸å¿ƒå†…å®¹
        clean_message = self.clean_psql_marker(message).strip()
        
        # å¦‚æœæ¶ˆæ¯æ˜¯æ¢ç´¢æ€§çš„æˆ–è€…åŒ…å«ä»‹ç»å…³é”®è¯ï¼Œéœ€è¦æ•°æ®åº“ä»‹ç»
        intro_keywords = ['ä»‹ç»', 'æœ‰ä»€ä¹ˆ', 'å“ªäº›è¡¨', 'æ•°æ®åº“', 'ç»“æ„', 'æ ·æœ¬', 'ç¤ºä¾‹']
        is_exploratory = (
            len(clean_message) <= 5 or 
            any(keyword in clean_message for keyword in intro_keywords) or
            '?' in clean_message or 
            'ï¼Ÿ' in clean_message
        )
        
        return is_exploratory

    def handle_database_introduction(self, user_message, session_id):
        """å¤„ç†æ•°æ®åº“ä»‹ç»æµç¨‹"""
        try:
            logger.info("ğŸ” å¼€å§‹æ•°æ®åº“ä»‹ç»æµç¨‹")
            
            # ä»ä¸‰ä¸ªè¡¨ä¸­è·å–æ ·æœ¬æ•°æ®
            sample_data = self.get_database_samples_detailed()
            if not sample_data:
                return self.error_response_dict("æ— æ³•è·å–æ•°æ®åº“æ ·æœ¬æ•°æ®")
            
            logger.info(f"è·å–åˆ°æ ·æœ¬æ•°æ®: {[k for k, v in sample_data.items() if v]}")
            
            # ä½¿ç”¨AIåˆ†ææ•°æ®åº“ç»“æ„
            schema_analysis = self.analyze_database_with_ai(sample_data)
            
            # ç”Ÿæˆç”¨æˆ·å‹å¥½çš„ä»‹ç»
            user_intro = self.generate_user_friendly_intro(schema_analysis)
            
            # æ ‡è®°æ•°æ®åº“å·²ç†è§£
            self.user_sessions[session_id]['database_understood'] = True
            
            # æ ¼å¼åŒ–å“åº”
            response_html = self.format_database_intro_response(user_intro, sample_data)
            
            return {
                'status': 'success',
                'response_type': 'database_intro', 
                'message': response_html,
                'has_samples': True,
                'database_understood': True
            }
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“ä»‹ç»æµç¨‹å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return self.error_response_dict(f"æ•°æ®åº“ä»‹ç»å¤±è´¥: {str(e)}")

    def get_database_samples_detailed(self):
        """ä»ä¸‰ä¸ªè¡¨ä¸­è·å–è¯¦ç»†çš„æ ·æœ¬æ•°æ®"""
        try:
            samples = {}
            tables = ['base_procurement_info_new', 'procurement_intention', 'procurement_notices']
            
            with connection.cursor() as cursor:
                for table in tables:
                    try:
                        # è·å–è¡¨ç»“æ„ä¿¡æ¯
                        cursor.execute(f"""
                            SELECT column_name, data_type, is_nullable 
                            FROM information_schema.columns 
                            WHERE table_name = '{table}' 
                            ORDER BY ordinal_position
                        """)
                        columns_info = cursor.fetchall()
                        
                        # è·å–æ ·æœ¬æ•°æ®
                        if table == 'procurement_notices':
                            # å¯¹äºå…¬å‘Šè¡¨ï¼Œé™åˆ¶contentå­—æ®µé•¿åº¦
                            cursor.execute(f"""
                                SELECT * FROM {table} 
                                WHERE publish_time IS NOT NULL 
                                ORDER BY publish_time DESC 
                                LIMIT 1
                            """)
                        else:
                            cursor.execute(f"""
                                SELECT * FROM {table} 
                                WHERE publish_time IS NOT NULL 
                                ORDER BY publish_time DESC 
                                LIMIT 1
                            """)
                        
                        sample_row = cursor.fetchone()
                        column_names = [col[0] for col in cursor.description]
                        
                        if sample_row:
                            # æ„å»ºæ ·æœ¬æ•°æ®å­—å…¸
                            sample_dict = {}
                            for i, col_name in enumerate(column_names):
                                value = sample_row[i]
                                # å¤„ç†é•¿æ–‡æœ¬å­—æ®µ
                                if col_name == 'content' and value and len(str(value)) > 200:
                                    value = str(value)[:200] + '...'
                                sample_dict[col_name] = value
                            
                            samples[table] = {
                                'structure': [{'name': col[0], 'type': col[1], 'nullable': col[2]} for col in columns_info],
                                'sample': sample_dict
                            }
                        else:
                            samples[table] = None
                            logger.warning(f"è¡¨ {table} ä¸­æ²¡æœ‰æ•°æ®")
                            
                    except Exception as e:
                        logger.error(f"è·å–è¡¨ {table} æ ·æœ¬å¤±è´¥: {e}")
                        samples[table] = None
            
            return samples
            
        except Exception as e:
            logger.error(f"è·å–æ•°æ®åº“æ ·æœ¬å¤±è´¥: {e}")
            return None

    def analyze_database_with_ai(self, sample_data):
        """ä½¿ç”¨AIåˆ†ææ•°æ®åº“ç»“æ„"""
        if not self.ai_client:
            return self.analyze_database_locally(sample_data)
        
        try:
            # å‡†å¤‡æ ·æœ¬æ•°æ®æè¿°
            sample_description = ""
            for table_name, table_data in sample_data.items():
                if table_data:
                    sample_description += f"\n\n{table_name} è¡¨ç¤ºä¾‹:\n"
                    sample_description += f"å­—æ®µç»“æ„: {[col['name'] for col in table_data['structure']]}\n"
                    sample_description += f"æ ·æœ¬æ•°æ®: {json.dumps(table_data['sample'], ensure_ascii=False, default=str)}"
            
            prompt = f"""
è¯·åˆ†æä»¥ä¸‹æ”¿åºœé‡‡è´­æ•°æ®åº“çš„ç»“æ„å’Œå†…å®¹ï¼š

è¿™æ˜¯ä¸€ä¸ªæ”¿åºœé‡‡è´­ä¿¡æ¯æ•°æ®åº“ï¼ŒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒæ•°æ®è¡¨ï¼š

1. base_procurement_info_new - åŸºç¡€é‡‡è´­ä¿¡æ¯è¡¨
2. procurement_intention - é‡‡è´­æ„å‘è¡¨  
3. procurement_notices - é‡‡è´­å…¬å‘Šè¡¨

å„è¡¨çš„æ ·æœ¬æ•°æ®å’Œç»“æ„å¦‚ä¸‹ï¼š
{sample_description}

è¯·è¯¦ç»†åˆ†æï¼š
1. æ¯ä¸ªè¡¨çš„ä¸»è¦åŠŸèƒ½å’Œä½œç”¨
2. å…³é”®å­—æ®µçš„å«ä¹‰å’Œç”¨é€”
3. è¡¨ä¹‹é—´çš„å…³ç³»å’Œå…³è”æ–¹å¼
4. æ•°æ®çš„ä¸šåŠ¡ä»·å€¼å’Œå…¸å‹ä½¿ç”¨åœºæ™¯
5. ç”¨æˆ·å¯ä»¥æŸ¥è¯¢å“ªäº›ç±»å‹çš„ä¿¡æ¯

è¯·ç”¨æ¸…æ™°çš„ä¸­æ–‡è¿›è¡Œåˆ†æï¼Œå¹¶ç»™å‡ºå…·ä½“çš„ä½¿ç”¨ç¤ºä¾‹ã€‚
"""
            
            response = self.ai_client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1500,
                temperature=0.3
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"AIæ•°æ®åº“åˆ†æå¤±è´¥: {e}")
            return self.analyze_database_locally(sample_data)

    def analyze_database_locally(self, sample_data):
        """æœ¬åœ°æ•°æ®åº“åˆ†æ"""
        analysis = """
## æ•°æ®åº“ç»“æ„åˆ†æ

### 1. åŸºç¡€é‡‡è´­ä¿¡æ¯è¡¨ (base_procurement_info_new)
- **åŠŸèƒ½**: å­˜å‚¨é‡‡è´­é¡¹ç›®çš„åŸºç¡€æ ¸å¿ƒä¿¡æ¯
- **å…³é”®å­—æ®µ**: 
  - url: å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºå…³è”å…¶ä»–è¡¨
  - title: é‡‡è´­é¡¹ç›®æ ‡é¢˜
  - jurisdiction: ç®¡è¾–åŒºåŸŸ
  - info_type: ä¿¡æ¯ç±»å‹ï¼ˆæ‹›æ ‡å…¬å‘Šã€ä¸­æ ‡å…¬ç¤ºç­‰ï¼‰
  - publish_time: å‘å¸ƒæ—¶é—´

### 2. é‡‡è´­æ„å‘è¡¨ (procurement_intention)  
- **åŠŸèƒ½**: å­˜å‚¨é‡‡è´­æ„å‘å’Œé¢„ç®—ä¿¡æ¯
- **å…³é”®å­—æ®µ**:
  - intention_budget_amount: é¢„ç®—é‡‘é¢
  - intention_procurement_unit: é‡‡è´­å•ä½
  - intention_project_name: é¡¹ç›®åç§°

### 3. é‡‡è´­å…¬å‘Šè¡¨ (procurement_notices)
- **åŠŸèƒ½**: å­˜å‚¨å®Œæ•´çš„é‡‡è´­å…¬å‘Šå†…å®¹
- **å…³é”®å­—æ®µ**:
  - content: è¯¦ç»†çš„å…¬å‘Šå†…å®¹ï¼ˆJSONæ ¼å¼ï¼‰

### è¡¨å…³ç³»
- ä¸‰ä¸ªè¡¨é€šè¿‡ `url` å­—æ®µè¿›è¡Œå…³è”
- base_procurement_info_new æ˜¯æ ¸å¿ƒè¡¨ï¼Œå…¶ä»–è¡¨é€šè¿‡urlä¸ä¹‹å…³è”

### å…¸å‹æŸ¥è¯¢ç¤ºä¾‹
- "æŸ¥è¯¢åŒ—äº¬å¸‚æœ€è¿‘çš„åŒ»ç–—è®¾å¤‡é‡‡è´­"
- "ç»Ÿè®¡2024å¹´å„åœ°åŒºçš„é‡‡è´­é¢„ç®—"
- "æ˜¾ç¤ºæ•™è‚²å±€çš„æ‹›æ ‡å…¬å‘Š"
- "åˆ†æåŒ»ç–—è¡Œä¸šçš„é‡‡è´­è¶‹åŠ¿"
"""
        return analysis

    def generate_user_friendly_intro(self, schema_analysis):
        """ç”Ÿæˆç”¨æˆ·å‹å¥½çš„ä»‹ç»"""
        if not self.ai_client:
            return self.generate_intro_locally(schema_analysis)
        
        try:
            prompt = f"""
åŸºäºä»¥ä¸‹æ•°æ®åº“åˆ†æï¼Œç”Ÿæˆä¸€æ®µå¯¹æ™®é€šç”¨æˆ·å‹å¥½çš„ä»‹ç»ï¼š

{schema_analysis}

è¦æ±‚ï¼š
1. ç”¨é€šä¿—æ˜“æ‡‚çš„ä¸­æ–‡ä»‹ç»æ•°æ®åº“
2. è¯´æ˜å¯ä»¥æŸ¥è¯¢å“ªäº›ä¿¡æ¯
3. ç»™å‡ºå…·ä½“çš„æŸ¥è¯¢ç¤ºä¾‹
4. è¯­æ°”å‹å¥½ã€æœ‰å¸®åŠ©æ€§

è¯·ç›´æ¥è¿”å›ä»‹ç»æ–‡å­—ã€‚
"""
            
            response = self.ai_client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=800,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"AIä»‹ç»ç”Ÿæˆå¤±è´¥: {e}")
            return self.generate_intro_locally(schema_analysis)

    def generate_intro_locally(self, schema_analysis):
        """ç”Ÿæˆæœ¬åœ°ä»‹ç»"""
        return """
## ğŸ›ï¸ æ”¿åºœé‡‡è´­æ•°æ®åº“ä»‹ç»

æˆ‘å·²æˆåŠŸè¿æ¥åˆ°æ”¿åºœé‡‡è´­æ•°æ®åº“ï¼Œè¿™é‡Œæœ‰ä¸°å¯Œçš„é‡‡è´­ä¿¡æ¯ä¾›æ‚¨æŸ¥è¯¢ï¼š

### ğŸ“Š æ•°æ®åº“åŒ…å«ä»€ä¹ˆï¼Ÿ
- **åŸºç¡€é‡‡è´­ä¿¡æ¯**: é¡¹ç›®æ ‡é¢˜ã€åœ°åŒºã€é‡‡è´­ç±»å‹ã€å‘å¸ƒæ—¶é—´ç­‰
- **é‡‡è´­æ„å‘**: é¢„ç®—é‡‘é¢ã€é‡‡è´­å•ä½ã€é¡¹ç›®è¯¦æƒ…  
- **é‡‡è´­å…¬å‘Š**: å®Œæ•´çš„å…¬å‘Šæ–‡æœ¬å’Œè¯¦ç»†å†…å®¹

### ğŸ” æ‚¨å¯ä»¥æŸ¥è¯¢ä»€ä¹ˆï¼Ÿ
- ç‰¹å®šåœ°åŒºçš„é‡‡è´­é¡¹ç›®ï¼ˆå¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·ï¼‰
- å„ç±»é‡‡è´­ç±»å‹ï¼ˆæ‹›æ ‡å…¬å‘Šã€ä¸­æ ‡å…¬ç¤ºã€é‡‡è´­æ„å‘ï¼‰
- é¢„ç®—é‡‘é¢åˆ†æå’Œç»Ÿè®¡
- æ—¶é—´èŒƒå›´å†…çš„é‡‡è´­åŠ¨æ€

### ğŸ’¡ æŸ¥è¯¢ç¤ºä¾‹
- "æ˜¾ç¤ºåŒ—äº¬å¸‚æœ€è¿‘çš„åŒ»ç–—è®¾å¤‡é‡‡è´­"
- "æŸ¥è¯¢æ•™è‚²å±€2024å¹´é‡‡è´­é¢„ç®—"  
- "ç»Ÿè®¡11æœˆä»½æ‹›æ ‡å…¬å‘Šæ•°é‡"
- "åˆ†æåŒ»ç–—è¡Œä¸šçš„é‡‡è´­è¶‹åŠ¿"

è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³äº†è§£ä»€ä¹ˆä¿¡æ¯ï¼Œæˆ‘ä¼šä¸ºæ‚¨ç”Ÿæˆè¯¦ç»†çš„æ•°æ®åˆ†ææŠ¥å‘Šï¼
"""

    def format_database_intro_response(self, introduction, sample_data):
        """æ ¼å¼åŒ–æ•°æ®åº“ä»‹ç»å“åº”"""
        html_parts = []
        
        html_parts.append("""
        <div class="database-intro-container">
            <div class="alert alert-info mb-4">
                <div class="d-flex align-items-center mb-3">
                    <span class="fs-4 me-2">ğŸ¯</span>
                    <h4 class="mb-0">æ•°æ®åº“è®¤çŸ¥å®Œæˆ</h4>
                </div>
        """)
        
        # æ·»åŠ ä»‹ç»å†…å®¹
        html_parts.append(f'<div class="intro-content">{introduction}</div>')
        
        html_parts.append("""
            </div>
            
            <div class="sample-preview">
                <h5 class="mb-3">ğŸ“‹ æ•°æ®æ ·æœ¬é¢„è§ˆ</h5>
                <div class="row g-3">
        """)
        
        # æ·»åŠ æ ·æœ¬æ•°æ®é¢„è§ˆ
        for table_name, table_data in sample_data.items():
            if table_data and table_data.get('sample'):
                sample = table_data['sample']
                html_parts.append(f"""
                    <div class="col-md-6 col-lg-4">
                        <div class="card h-100">
                            <div class="card-header bg-primary text-white">
                                <strong>{self.format_table_name(table_name)}</strong>
                            </div>
                            <div class="card-body">
                                {self.format_sample_preview(sample)}
                            </div>
                        </div>
                    </div>
                """)
        
        html_parts.append("""
                </div>
            </div>
            
            <div class="mt-4 alert alert-success">
                <strong>ğŸ’¡ æç¤º:</strong> ç°åœ¨æ‚¨å¯ä»¥æå‡ºå…·ä½“çš„æ•°æ®æŸ¥è¯¢éœ€æ±‚äº†ï¼
                ä¾‹å¦‚ï¼š"æŸ¥è¯¢11æœˆåŒ»ç–—è¡Œä¸šçš„é‡‡è´­æ„å‘" æˆ– "æ˜¾ç¤ºæœ€è¿‘çš„æ‹›æ ‡å…¬å‘Š"
            </div>
        </div>
        """)
        
        return "".join(html_parts)

    def format_table_name(self, table_name):
        """æ ¼å¼åŒ–è¡¨åæ˜¾ç¤º"""
        name_map = {
            'base_procurement_info_new': 'åŸºç¡€é‡‡è´­ä¿¡æ¯',
            'procurement_intention': 'é‡‡è´­æ„å‘', 
            'procurement_notices': 'é‡‡è´­å…¬å‘Š'
        }
        return name_map.get(table_name, table_name)

    def format_sample_preview(self, sample):
        """æ ¼å¼åŒ–æ ·æœ¬æ•°æ®é¢„è§ˆ"""
        preview_html = []
        key_fields = ['title', 'jurisdiction', 'info_type', 'publish_time', 
                     'intention_budget_amount', 'intention_procurement_unit']
        
        for field in key_fields:
            if field in sample and sample[field]:
                value = sample[field]
                display_value = str(value)
                if len(display_value) > 30:
                    display_value = display_value[:30] + '...'
                
                field_name = self.format_header_name(field)
                preview_html.append(f"""
                    <div class="mb-2">
                        <small><strong>{field_name}:</strong> {display_value}</small>
                    </div>
                """)
        
        return "".join(preview_html)

    def handle_intelligent_data_analysis(self, user_message, session_id):
        """æ™ºèƒ½æ•°æ®åˆ†æå¤„ç† - æ·±åº¦ç†è§£ã€å†…å®¹æå–ã€æ™ºèƒ½å›ç­”"""
        try:
            # æ¸…ç†æ¶ˆæ¯
            clean_message = self.clean_psql_marker(user_message)
            logger.info(f"å¼€å§‹æ™ºèƒ½æ•°æ®åˆ†æ: {clean_message}")
            
            # è·å–å¯¹è¯å†å²
            conversation_history = self.user_sessions[session_id].get('conversation_history', [])
            
            # æ·±åº¦ç†è§£ç”¨æˆ·æ„å›¾
            intent_analysis = self.analyze_user_intent(clean_message)
            
            # æ ¹æ®æ„å›¾é€‰æ‹©æŸ¥è¯¢ç­–ç•¥
            if self.requires_content_analysis(intent_analysis):
                return self.handle_intelligent_content_analysis(clean_message, intent_analysis, session_id, conversation_history)
            else:
                return self.handle_basic_data_query(clean_message, intent_analysis, session_id)
                
        except Exception as e:
            logger.error(f"æ™ºèƒ½æ•°æ®åˆ†æå¤„ç†å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return self.error_response_dict(f"æ•°æ®åˆ†æå¤±è´¥: {str(e)}")

    def analyze_user_intent(self, user_message):
        """æ·±åº¦åˆ†æç”¨æˆ·æ„å›¾"""
        medical_keywords = ['åŒ»ç–—', 'åŒ»é™¢', 'è¯å“', 'å™¨æ¢°', 'ä¿å¥', 'å«ç”Ÿ', 'åŒ»å­¦', 'åŒ»ä¿', 'è¯Šç–—']
        intention_keywords = ['æ„å‘', 'é‡‡è´­æ„å‘', 'é¢„ç®—']
        notice_keywords = ['å…¬å‘Š', 'æ‹›æ ‡', 'ä¸­æ ‡', 'è¦æ±‚', 'èµ„è´¨', 'è”ç³»äºº', 'å†…å®¹']
        
        intent = {
            'industry': 'åŒ»ç–—' if any(kw in user_message for kw in medical_keywords) else 'é€šç”¨',
            'query_type': 'æ„å‘' if any(kw in user_message for kw in intention_keywords) else 
                         'å…¬å‘Š' if any(kw in user_message for kw in notice_keywords) else 'é€šç”¨',
            'time_range': '11æœˆ' if '11æœˆ' in user_message or 'åä¸€æœˆ' in user_message else 
                         'è¿‘æœŸ' if 'æœ€è¿‘' in user_message or 'æœ€æ–°' in user_message else '',
            'needs_contact': 'è”ç³»äºº' in user_message or 'è”ç³»' in user_message or 'ç”µè¯' in user_message,
            'needs_qualification': 'èµ„è´¨' in user_message or 'è¦æ±‚' in user_message or 'æ¡ä»¶' in user_message,
            'needs_content': 'å†…å®¹' in user_message or 'è¯¦æƒ…' in user_message or 'è¦æ±‚' in user_message,
            'needs_url': 'ç½‘å€' in user_message or 'é“¾æ¥' in user_message
        }
        
        logger.info(f"ç”¨æˆ·æ„å›¾åˆ†æ: {intent}")
        return intent

    def requires_content_analysis(self, intent_analysis):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å†…å®¹åˆ†æ"""
        return (intent_analysis['needs_contact'] or 
                intent_analysis['needs_qualification'] or 
                intent_analysis['needs_content'] or
                intent_analysis['query_type'] == 'å…¬å‘Š')

    def handle_intelligent_content_analysis(self, user_message, intent_analysis, session_id, conversation_history):
        """å¤„ç†æ™ºèƒ½å†…å®¹åˆ†æ"""
        try:
            # è·å–ç›¸å…³æ•°æ®ï¼ˆåŒ…å«contentå­—æ®µï¼‰
            raw_data = self.get_content_rich_data(intent_analysis)
            
            if not raw_data:
                return self.format_no_data_response(user_message)
            
            # æ·±åº¦åˆ†æcontentå†…å®¹
            analyzed_results = self.analyze_content_data(raw_data, intent_analysis)
            
            # ç”Ÿæˆæ™ºèƒ½å›ç­”
            intelligent_response = self.generate_intelligent_response(
                user_message, analyzed_results, intent_analysis, conversation_history
            )
            
            response_data = {
                'status': 'success',
                'response_type': 'intelligent_analysis',
                'message': intelligent_response,
                'data_count': len(raw_data),
                'analysis_depth': 'deep',
                'formatted': True
            }
            
            logger.info(f"æ™ºèƒ½åˆ†æå®Œæˆï¼Œè¿”å› {len(raw_data)} æ¡æ•°æ®çš„åˆ†æç»“æœ")
            return response_data
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½å†…å®¹åˆ†æå¤±è´¥: {e}")
            # é™çº§å¤„ç†
            return self.handle_basic_data_query(user_message, intent_analysis, session_id)

    def get_content_rich_data(self, intent_analysis):
        """è·å–åŒ…å«contentå­—æ®µçš„è¯¦ç»†æ•°æ®"""
        try:
            base_query = """
            SELECT 
                base.url, base.title, base.jurisdiction, base.info_type, base.publish_time,
                notices.content as notice_content,
                intention.intention_budget_amount, intention.intention_procurement_unit,
                intention.intention_project_name
            FROM base_procurement_info_new base
            LEFT JOIN procurement_notices notices ON base.url = notices.url
            LEFT JOIN procurement_intention intention ON base.url = intention.url
            WHERE 1=1
            """
            
            conditions = self.build_intelligent_conditions(intent_analysis)
            
            if conditions:
                base_query += " AND " + " AND ".join(conditions)
            
            base_query += " ORDER BY base.publish_time DESC LIMIT 100"
            
            logger.info(f"æ™ºèƒ½æŸ¥è¯¢SQL: {base_query}")
            
            with connection.cursor() as cursor:
                cursor.execute(base_query)
                columns = [col[0] for col in cursor.description]
                rows = cursor.fetchall()
                
                results = []
                for row in rows:
                    row_dict = {}
                    for i, col in enumerate(columns):
                        # ç‰¹åˆ«å¤„ç†contentå­—æ®µ
                        if col == 'notice_content' and row[i]:
                            try:
                                # å°è¯•è§£æJSONæ ¼å¼çš„content
                                if isinstance(row[i], str) and row[i].strip().startswith('{'):
                                    content_data = json.loads(row[i])
                                    row_dict[col] = content_data
                                else:
                                    row_dict[col] = str(row[i])
                            except:
                                # è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡æœ¬
                                row_dict[col] = str(row[i])
                        else:
                            row_dict[col] = row[i]
                    results.append(row_dict)
                
                return results
                
        except Exception as e:
            logger.error(f"è·å–è¯¦ç»†æ•°æ®å¤±è´¥: {e}")
            return None

    def build_intelligent_conditions(self, intent_analysis):
        """æ„å»ºæ™ºèƒ½æŸ¥è¯¢æ¡ä»¶"""
        conditions = []
        
        # è¡Œä¸šæ¡ä»¶
        if intent_analysis['industry'] == 'åŒ»ç–—':
            medical_keywords = ['åŒ»ç–—', 'åŒ»é™¢', 'è¯å“', 'å™¨æ¢°', 'ä¿å¥', 'å«ç”Ÿ', 'åŒ»å­¦', 'åŒ»ä¿']
            medical_conds = [f"base.title LIKE '%{kw}%'" for kw in medical_keywords]
            conditions.append("(" + " OR ".join(medical_conds) + ")")
        
        # æ—¶é—´æ¡ä»¶
        if intent_analysis['time_range'] == '11æœˆ':
            current_year = datetime.now().year
            conditions.append(f"EXTRACT(MONTH FROM base.publish_time) = 11")
            conditions.append(f"EXTRACT(YEAR FROM base.publish_time) = {current_year}")
        elif intent_analysis['time_range'] == 'è¿‘æœŸ':
            conditions.append(f"base.publish_time >= CURRENT_DATE - INTERVAL '30 days'")
        
        # ç±»å‹æ¡ä»¶
        if intent_analysis['query_type'] == 'æ„å‘':
            conditions.append("base.info_type LIKE '%æ„å‘%'")
        elif intent_analysis['query_type'] == 'å…¬å‘Š':
            conditions.append("(base.info_type LIKE '%å…¬å‘Š%' OR base.info_type LIKE '%æ‹›æ ‡%' OR base.info_type LIKE '%ä¸­æ ‡%')")
        
        # ç¡®ä¿åªæŸ¥è¯¢æœ‰æ•ˆæ•°æ®
        conditions.append("base.publish_time IS NOT NULL")
        conditions.append("base.title IS NOT NULL")
        
        return conditions

    def analyze_content_data(self, raw_data, intent_analysis):
        """æ·±åº¦åˆ†æå†…å®¹æ•°æ®"""
        analyzed_results = []
        
        for item in raw_data:
            analysis = {
                'title': item.get('title', ''),
                'url': item.get('url', ''),
                'publish_time': item.get('publish_time', ''),
                'jurisdiction': item.get('jurisdiction', ''),
                'info_type': item.get('info_type', ''),
                'budget': item.get('intention_budget_amount'),
                'procurement_unit': item.get('intention_procurement_unit'),
                'project_name': item.get('intention_project_name'),
                'extracted_info': {}
            }
            
            # ä»contentä¸­æå–å…³é”®ä¿¡æ¯
            content = item.get('notice_content', '')
            if content:
                # æå–æ–‡æœ¬å†…å®¹
                content_text = self.extract_text_from_content(content)
                
                # æå–è”ç³»äººä¿¡æ¯
                if intent_analysis['needs_contact']:
                    analysis['extracted_info']['contact'] = self.extract_contact_info(content_text)
                
                # æå–èµ„è´¨è¦æ±‚
                if intent_analysis['needs_qualification']:
                    analysis['extracted_info']['qualifications'] = self.extract_qualification_info(content_text)
                
                # æå–å…¶ä»–å…³é”®ä¿¡æ¯
                analysis['extracted_info']['key_points'] = self.extract_key_points(content_text, intent_analysis)
                
                # æå–ä¸»è¦å†…å®¹æ‘˜è¦
                analysis['extracted_info']['content_summary'] = self.extract_content_summary(content_text)
            
            analyzed_results.append(analysis)
        
        return analyzed_results

    def extract_text_from_content(self, content):
        """ä»contentä¸­æå–æ–‡æœ¬"""
        if isinstance(content, str):
            return content
        elif isinstance(content, dict):
            # ä»å­—å…¸ä¸­æå–æ–‡æœ¬å†…å®¹
            text_parts = []
            for key, value in content.items():
                if isinstance(value, str) and len(value.strip()) > 10:
                    text_parts.append(value.strip())
                elif isinstance(value, (list, dict)):
                    # é€’å½’å¤„ç†åµŒå¥—ç»“æ„
                    try:
                        nested_text = json.dumps(value, ensure_ascii=False)
                        if len(nested_text) > 20:
                            text_parts.append(nested_text)
                    except:
                        pass
            return " ".join(text_parts)
        else:
            return str(content)

    def extract_contact_info(self, text):
        """æå–è”ç³»äººä¿¡æ¯"""
        contact_info = {}
        
        # è”ç³»äººå§“å
        name_patterns = [
            r'è”ç³»äºº[ï¼š:]\s*([^\sï¼Œã€‚]{2,10}?)(?=[ï¼Œã€‚\s]|$)',
            r'è”ç³»äººå‘˜[ï¼š:]\s*([^\sï¼Œã€‚]{2,10}?)(?=[ï¼Œã€‚\s]|$)',
            r'é¡¹ç›®è”ç³»äºº[ï¼š:]\s*([^\sï¼Œã€‚]{2,10}?)(?=[ï¼Œã€‚\s]|$)',
            r'è”ç³»äººå§“å[ï¼š:]\s*([^\sï¼Œã€‚]{2,10}?)(?=[ï¼Œã€‚\s]|$)'
        ]
        
        for pattern in name_patterns:
            matches = re.findall(pattern, text)
            if matches:
                contact_info['person'] = matches[0].strip()
                break
        
        # è”ç³»ç”µè¯
        phone_patterns = [
            r'ç”µè¯[ï¼š:]\s*([0-9-()ï¼ˆï¼‰]{7,15}?)(?=[ï¼Œã€‚\s]|$)',
            r'è”ç³»ç”µè¯[ï¼š:]\s*([0-9-()ï¼ˆï¼‰]{7,15}?)(?=[ï¼Œã€‚\s]|$)',
            r'è”ç³»æ–¹å¼[ï¼š:]\s*([0-9-()ï¼ˆï¼‰]{7,15}?)(?=[ï¼Œã€‚\s]|$)',
            r'æ‰‹æœº[ï¼š:]\s*([0-9-()ï¼ˆï¼‰]{7,15}?)(?=[ï¼Œã€‚\s]|$)'
        ]
        
        for pattern in phone_patterns:
            matches = re.findall(pattern, text)
            if matches:
                contact_info['phone'] = matches[0].strip()
                break
        
        return contact_info if contact_info else {"info": "è¯¦è§å…¬å‘Šå†…å®¹"}

    def extract_qualification_info(self, text):
        """æå–èµ„è´¨è¦æ±‚ä¿¡æ¯"""
        qualifications = []
        
        # èµ„è´¨è¦æ±‚æ®µè½æå–
        qual_patterns = [
            r'èµ„è´¨è¦æ±‚[ï¼š:](.*?)(?=æŠ•æ ‡äººèµ„æ ¼|ç”³è¯·äººèµ„æ ¼|èµ„æ ¼æ¡ä»¶|$)',
            r'æŠ•æ ‡äººèµ„æ ¼[ï¼š:](.*?)(?=èµ„è´¨è¦æ±‚|ç”³è¯·äººèµ„æ ¼|èµ„æ ¼æ¡ä»¶|$)',
            r'ç”³è¯·äººèµ„æ ¼[ï¼š:](.*?)(?=èµ„è´¨è¦æ±‚|æŠ•æ ‡äººèµ„æ ¼|èµ„æ ¼æ¡ä»¶|$)',
            r'èµ„æ ¼æ¡ä»¶[ï¼š:](.*?)(?=èµ„è´¨è¦æ±‚|æŠ•æ ‡äººèµ„æ ¼|ç”³è¯·äººèµ„æ ¼|$)'
        ]
        
        for pattern in qual_patterns:
            matches = re.findall(pattern, text, re.DOTALL)
            for match in matches:
                # æ¸…ç†åŒ¹é…ç»“æœ
                cleaned = match.strip()
                if len(cleaned) > 10:  # ç¡®ä¿æœ‰å®é™…å†…å®¹
                    qualifications.append(cleaned)
        
        # å¦‚æœæ²¡æ‰¾åˆ°å®Œæ•´æ®µè½ï¼Œæå–å…³é”®è¯å‘¨å›´çš„å¥å­
        if not qualifications:
            qual_keywords = ['èµ„è´¨', 'èµ„æ ¼', 'è¦æ±‚', 'æ¡ä»¶', 'å…·å¤‡']
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
            for sentence in sentences:
                if any(keyword in sentence for keyword in qual_keywords) and len(sentence) > 15:
                    qualifications.append(sentence.strip())
        
        return qualifications[:3] if qualifications else ["å…·ä½“èµ„è´¨è¦æ±‚è¯·æŸ¥çœ‹å®Œæ•´å…¬å‘Šå†…å®¹"]

    def extract_key_points(self, text, intent_analysis):
        """æå–å…³é”®ä¿¡æ¯ç‚¹"""
        key_points = []
        
        # æ ¹æ®ç”¨æˆ·æ„å›¾æå–ç›¸å…³ä¿¡æ¯
        if intent_analysis['industry'] == 'åŒ»ç–—':
            medical_terms = ['åŒ»ç–—è®¾å¤‡', 'åŒ»ç–—å™¨æ¢°', 'è¯å“', 'åŒ»ç–—æœåŠ¡', 'åŒ»ç–—æŠ€æœ¯', 'åŒ»é™¢', 'å«ç”Ÿ']
            for term in medical_terms:
                if term in text:
                    key_points.append(f"æ¶‰åŠ{term}é‡‡è´­")
        
        # æå–æ—¶é—´ä¿¡æ¯
        time_patterns = [
            r'æŠ•æ ‡æˆªæ­¢[æ—¶é—´]*[ï¼š:]\s*([^ï¼Œã€‚]{10,30}?)(?=[ï¼Œã€‚\s]|$)',
            r'å¼€æ ‡æ—¶é—´[ï¼š:]\s*([^ï¼Œã€‚]{10,30}?)(?=[ï¼Œã€‚\s]|$)',
            r'æŠ¥åæ—¶é—´[ï¼š:]\s*([^ï¼Œã€‚]{10,30}?)(?=[ï¼Œã€‚\s]|$)'
        ]
        
        for pattern in time_patterns:
            matches = re.findall(pattern, text)
            if matches:
                key_points.append(f"é‡è¦æ—¶é—´: {matches[0]}")
        
        # æå–é¢„ç®—ä¿¡æ¯
        if 'é¢„ç®—' in text or 'é‡‘é¢' in text:
            budget_patterns = [
                r'é¢„ç®—[é‡‘é¢]*[ï¼š:]\s*([^ï¼Œã€‚]{5,20}?)(?=[ï¼Œã€‚\s]|$)',
                r'é¡¹ç›®é‡‘é¢[ï¼š:]\s*([^ï¼Œã€‚]{5,20}?)(?=[ï¼Œã€‚\s]|$)'
            ]
            for pattern in budget_patterns:
                matches = re.findall(pattern, text)
                if matches:
                    key_points.append(f"é¢„ç®—ä¿¡æ¯: {matches[0]}")
        
        return key_points[:5]  # æœ€å¤šè¿”å›5ä¸ªå…³é”®ç‚¹

    def extract_content_summary(self, text):
        """æå–å†…å®¹æ‘˜è¦"""
        # å–å‰200ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦
        if len(text) > 200:
            return text[:200] + "..."
        return text

    def generate_intelligent_response(self, user_message, analyzed_results, intent_analysis, conversation_history):
        """ç”Ÿæˆæ™ºèƒ½å›ç­”"""
        if not analyzed_results:
            return self.format_no_data_response(user_message)
        
        # ä½¿ç”¨AIç”Ÿæˆæ™ºèƒ½å›ç­”ï¼ˆå¦‚æœæœ‰AIå®¢æˆ·ç«¯ï¼‰
        if self.ai_client:
            try:
                return self.generate_ai_enhanced_response(user_message, analyzed_results, intent_analysis, conversation_history)
            except Exception as e:
                logger.error(f"AIå¢å¼ºå›ç­”ç”Ÿæˆå¤±è´¥: {e}")
        
        # é™çº§åˆ°æ¨¡æ¿å›ç­”
        return self.generate_template_response(user_message, analyzed_results, intent_analysis)

    def generate_ai_enhanced_response(self, user_message, analyzed_results, intent_analysis, conversation_history):
        """ä½¿ç”¨AIç”Ÿæˆå¢å¼ºå›ç­”"""
        # å‡†å¤‡æ•°æ®æ‘˜è¦
        data_summary = self.prepare_data_summary_for_ai(analyzed_results)
        
        # å‡†å¤‡å¯¹è¯å†å²ä¸Šä¸‹æ–‡
        history_context = self.prepare_conversation_history(conversation_history[-4:])  # æœ€è¿‘2è½®å¯¹è¯
        
        prompt = f"""
ä½œä¸ºæ”¿åºœé‡‡è´­æ•°æ®åˆ†æä¸“å®¶ï¼Œè¯·åŸºäºä»¥ä¸‹æ•°æ®å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·å½“å‰é—®é¢˜ï¼š{user_message}

å¯¹è¯å†å²ä¸Šä¸‹æ–‡ï¼š
{history_context}

æŸ¥è¯¢åˆ°çš„æ•°æ®æ‘˜è¦ï¼ˆå…±{len(analyzed_results)}æ¡è®°å½•ï¼‰ï¼š
{data_summary}

ç”¨æˆ·å…³æ³¨çš„é‡ç‚¹ï¼š
- è¡Œä¸šé¢†åŸŸï¼š{intent_analysis['industry']}
- æŸ¥è¯¢ç±»å‹ï¼š{intent_analysis['query_type']}
- æ—¶é—´èŒƒå›´ï¼š{intent_analysis['time_range']}
- éœ€è¦è”ç³»äººä¿¡æ¯ï¼š{'æ˜¯' if intent_analysis['needs_contact'] else 'å¦'}
- éœ€è¦èµ„è´¨è¦æ±‚ï¼š{'æ˜¯' if intent_analysis['needs_qualification'] else 'å¦'}

å›ç­”è¦æ±‚ï¼š
1. ç›´æ¥ã€å‡†ç¡®åœ°å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸è¦æåŠSQLæˆ–æŠ€æœ¯ç»†èŠ‚
2. åŸºäºå®é™…æ•°æ®å¼•ç”¨å…·ä½“ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€é¢„ç®—ã€è”ç³»äººç­‰ï¼‰
3. å¯¹ä¿¡æ¯è¿›è¡Œæ€»ç»“åˆ†æï¼Œæä¾›ä¸šåŠ¡æ´å¯Ÿ
4. ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„ä¸­æ–‡ï¼Œç»“æ„æ¸…æ™°
5. å¯¹äºèµ„è´¨è¦æ±‚ã€è”ç³»äººç­‰è¯¦ç»†ä¿¡æ¯ï¼Œè¦å…·ä½“å¼•ç”¨å†…å®¹
6. å¦‚æœæ•°æ®è¾ƒå¤šï¼Œè¿›è¡Œåˆ†ç±»æ€»ç»“

è¯·ç”Ÿæˆä¸“ä¸šã€æœ‰ç”¨çš„å›ç­”ï¼š
"""
        
        response = self.ai_client.chat.completions.create(
            model=self.model_name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2000,
            temperature=0.3
        )
        
        return f"""
        <div class="intelligent-analysis-result">
            <div class="alert alert-success">
                <h4>ğŸ§  æ™ºèƒ½åˆ†æç»“æœ</h4>
                <p><strong>æ‚¨çš„æŸ¥è¯¢ï¼š</strong> {user_message}</p>
            </div>
            <div class="analysis-content">
                {response.choices[0].message.content}
            </div>
            <div class="mt-3 alert alert-info">
                <small>ğŸ“Š åŸºäº {len(analyzed_results)} æ¡ç›¸å…³æ•°æ®è¿›è¡Œçš„æ·±åº¦åˆ†æ</small>
            </div>
        </div>
        """

    def prepare_data_summary_for_ai(self, analyzed_results):
        """ä¸ºAIå‡†å¤‡æ•°æ®æ‘˜è¦"""
        if not analyzed_results:
            return "æœªæ‰¾åˆ°ç›¸å…³æ•°æ®"
        
        summary = f"å…±æ‰¾åˆ° {len(analyzed_results)} æ¡ç›¸å…³è®°å½•ï¼š\n\n"
        
        for i, result in enumerate(analyzed_results[:10], 1):  # æœ€å¤š10æ¡
            summary += f"{i}. {result.get('title', 'æ— æ ‡é¢˜')}\n"
            summary += f"   åœ°åŒºï¼š{result.get('jurisdiction', 'æœªçŸ¥')} | ç±»å‹ï¼š{result.get('info_type', 'æœªçŸ¥')}\n"
            summary += f"   æ—¶é—´ï¼š{result.get('publish_time', 'æœªçŸ¥')}\n"
            
            if result.get('budget'):
                summary += f"   é¢„ç®—ï¼š{result.get('budget')}å…ƒ\n"
            
            # è”ç³»äººä¿¡æ¯
            if result['extracted_info'].get('contact'):
                contact = result['extracted_info']['contact']
                if contact.get('person'):
                    summary += f"   è”ç³»äººï¼š{contact['person']}"
                    if contact.get('phone'):
                        summary += f" | ç”µè¯ï¼š{contact['phone']}"
                    summary += "\n"
            
            # èµ„è´¨è¦æ±‚
            if result['extracted_info'].get('qualifications'):
                quals = result['extracted_info']['qualifications']
                summary += f"   èµ„è´¨è¦æ±‚ï¼š{quals[0][:50]}...\n"
            
            summary += "\n"
        
        if len(analyzed_results) > 10:
            summary += f"... è¿˜æœ‰ {len(analyzed_results) - 10} æ¡è®°å½•\n"
        
        return summary

    def prepare_conversation_history(self, history):
        """å‡†å¤‡å¯¹è¯å†å²"""
        if not history:
            return "æ— å†å²å¯¹è¯"
        
        formatted = []
        for msg in history:
            role = "ç”¨æˆ·" if msg['role'] == 'user' else "åŠ©æ‰‹"
            # æˆªæ–­è¿‡é•¿çš„æ¶ˆæ¯
            content = msg['content']
            if len(content) > 100:
                content = content[:100] + "..."
            formatted.append(f"{role}: {content}")
        
        return "\n".join(formatted)

    def generate_template_response(self, user_message, analyzed_results, intent_analysis):
        """ç”Ÿæˆæ¨¡æ¿å›ç­”"""
        if not analyzed_results:
            return self.format_no_data_response(user_message)
        
        html_parts = []
        
        html_parts.append(f"""
        <div class="intelligent-analysis-result">
            <div class="alert alert-success">
                <h4>ğŸ“Š æ™ºèƒ½åˆ†æç»“æœ</h4>
                <p><strong>æ‚¨çš„æŸ¥è¯¢ï¼š</strong> {user_message}</p>
                <p><strong>æ‰¾åˆ°ç›¸å…³é¡¹ç›®ï¼š</strong> {len(analyzed_results)} ä¸ª</p>
            </div>
        """)
        
        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        grouped_results = {}
        for result in analyzed_results:
            info_type = result.get('info_type', 'å…¶ä»–')
            if info_type not in grouped_results:
                grouped_results[info_type] = []
            grouped_results[info_type].append(result)
        
        for info_type, items in grouped_results.items():
            html_parts.append(f"""
            <div class="mb-4">
                <h5>{info_type} ({len(items)}ä¸ª)</h5>
            """)
            
            for i, item in enumerate(items[:5], 1):  # æ¯ç»„æœ€å¤šæ˜¾ç¤º5ä¸ª
                html_parts.append(self.format_single_item_html(item, i))
            
            if len(items) > 5:
                html_parts.append(f'<p class="text-muted">... è¿˜æœ‰ {len(items) - 5} ä¸ª{info_type}é¡¹ç›®</p>')
            
            html_parts.append("</div>")
        
        html_parts.append("</div>")
        return "".join(html_parts)

    def format_single_item_html(self, item, index):
        """æ ¼å¼åŒ–å•ä¸ªé¡¹ç›®æ˜¾ç¤º"""
        html = f"""
        <div class="card mb-3">
            <div class="card-body">
                <h6 class="card-title">{index}. {item.get('title', 'æ— æ ‡é¢˜')}</h6>
                <div class="row">
                    <div class="col-md-6">
                        <small><strong>åœ°åŒºï¼š</strong>{item.get('jurisdiction', 'æœªçŸ¥')}</small><br>
                        <small><strong>æ—¶é—´ï¼š</strong>{item.get('publish_time', 'æœªçŸ¥')}</small>
                    </div>
                    <div class="col-md-6">
        """
        
        if item.get('budget'):
            html += f'<small><strong>é¢„ç®—ï¼š</strong>Â¥{item.get("budget"):,.2f}</small><br>'
        
        if item.get('procurement_unit'):
            html += f'<small><strong>é‡‡è´­å•ä½ï¼š</strong>{item.get("procurement_unit")}</small>'
        
        html += """
                    </div>
                </div>
        """
        
        # æ˜¾ç¤ºæå–çš„ä¿¡æ¯
        if item['extracted_info'].get('contact'):
            contact = item['extracted_info']['contact']
            if contact.get('person') or contact.get('phone'):
                html += '<div class="mt-2"><small><strong>ğŸ“ è”ç³»æ–¹å¼ï¼š</strong>'
                if contact.get('person'):
                    html += f'{contact["person"]} '
                if contact.get('phone'):
                    html += f'{contact["phone"]}'
                html += '</small></div>'
        
        if item['extracted_info'].get('qualifications'):
            quals = item['extracted_info']['qualifications']
            html += f'<div class="mt-1"><small><strong>ğŸ“‹ èµ„è´¨è¦æ±‚ï¼š</strong>{quals[0][:80]}...</small></div>'
        
        if item.get('url'):
            html += f'<div class="mt-2"><a href="{item["url"]}" target="_blank" class="btn btn-sm btn-outline-primary">æŸ¥çœ‹è¯¦ç»†å…¬å‘Š</a></div>'
        
        html += """
            </div>
        </div>
        """
        return html

    def format_no_data_response(self, user_message):
        """æ ¼å¼åŒ–æ— æ•°æ®å“åº”"""
        return f"""
        <div class="alert alert-warning">
            <h4>ğŸ” æŸ¥è¯¢ç»“æœ</h4>
            <p>æœªæ‰¾åˆ°ä¸ "<strong>{user_message}</strong>" ç›¸å…³çš„é‡‡è´­ä¿¡æ¯ã€‚</p>
            <p>å»ºè®®ï¼š</p>
            <ul>
                <li>æ£€æŸ¥æŸ¥è¯¢æ¡ä»¶æ˜¯å¦è¿‡äºå…·ä½“</li>
                <li>å°è¯•æ›´å¹¿æ³›çš„å…³é”®è¯æœç´¢</li>
                <li>ç¡®è®¤æ—¶é—´èŒƒå›´æ˜¯å¦åˆé€‚</li>
            </ul>
        </div>
        """

    def handle_basic_data_query(self, user_message, intent_analysis, session_id):
        """å¤„ç†åŸºç¡€æ•°æ®æŸ¥è¯¢ï¼ˆå…¼å®¹åŸæœ‰é€»è¾‘ï¼‰"""
        try:
            # åŸæœ‰çš„ç®€å•æŸ¥è¯¢é€»è¾‘
            target_tables = self.select_target_tables(user_message)
            sql_query = self.generate_sql_query(user_message, target_tables)
            
            if not sql_query:
                return self.error_response_dict("æ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„SQLæŸ¥è¯¢")
            
            query_result = self.execute_sql_query(sql_query)
            if query_result is None:
                return self.error_response_dict("æ•°æ®åº“æŸ¥è¯¢å¤±è´¥")
            
            analysis_result = self.analyze_query_results(user_message, query_result, target_tables)
            final_response = self.format_data_analysis_response(
                user_message, sql_query, query_result, analysis_result, target_tables
            )
            
            return final_response
            
        except Exception as e:
            logger.error(f"åŸºç¡€æ•°æ®æŸ¥è¯¢å¤±è´¥: {e}")
            return self.error_response_dict(f"æŸ¥è¯¢å¤±è´¥: {str(e)}")

    # ä¿ç•™åŸæœ‰çš„å…¼å®¹æ€§æ–¹æ³•
    def select_target_tables(self, user_message):
        """é€‰æ‹©ç›®æ ‡è¡¨"""
        message_lower = user_message.lower()
        
        if 'æ„å‘' in message_lower or 'é¢„ç®—' in message_lower:
            return 'procurement_intention'
        elif 'å…¬å‘Š' in message_lower or 'å†…å®¹' in message_lower:
            return 'procurement_notices'
        else:
            return 'base_procurement_info_new'

    def generate_sql_query(self, natural_language_query, target_tables):
        """ç”ŸæˆSQLæŸ¥è¯¢"""
        query_lower = natural_language_query.lower()
        
        # æ„å»ºåŸºç¡€æŸ¥è¯¢
        if isinstance(target_tables, list):
            base_sql = """
            SELECT 
                base.url, base.title, base.jurisdiction, base.info_type, base.publish_time,
                intention.intention_budget_amount, intention.intention_procurement_unit
            FROM base_procurement_info_new base
            LEFT JOIN procurement_intention intention ON base.url = intention.url
            WHERE 1=1
            """
        else:
            if target_tables == 'procurement_intention':
                base_sql = """
                SELECT url, title, jurisdiction, info_type, publish_time, 
                       intention_budget_amount, intention_procurement_unit 
                FROM procurement_intention WHERE 1=1
                """
            elif target_tables == 'procurement_notices':
                base_sql = """
                SELECT url, title, jurisdiction, info_type, publish_time, 
                       LEFT(content::text, 200) as content_preview
                FROM procurement_notices WHERE 1=1
                """
            else:
                base_sql = "SELECT url, title, jurisdiction, info_type, publish_time FROM base_procurement_info_new WHERE 1=1"
        
        # æ·»åŠ æ¡ä»¶
        conditions = self.build_sql_conditions(query_lower, target_tables)
        
        if conditions:
            base_sql += " AND " + " AND ".join(conditions)
        
        # æ·»åŠ æ’åº
        base_sql = self.add_ordering(base_sql, query_lower, target_tables)
        
        # é™åˆ¶ç»“æœæ•°é‡
        base_sql += " LIMIT 100"
        
        return base_sql

    def build_sql_conditions(self, query_lower, target_table):
        """æ„å»ºSQLæ¡ä»¶"""
        conditions = []
        
        # åŒ»ç–—è¡Œä¸šå…³é”®è¯
        medical_keywords = ['åŒ»ç–—', 'åŒ»é™¢', 'è¯å“', 'å™¨æ¢°', 'ä¿å¥', 'å«ç”Ÿ', 'åŒ»å­¦', 'åŒ»ä¿', 'è¯Šç–—', 'å«ç”Ÿé™¢']
        medical_matches = [kw for kw in medical_keywords if kw in query_lower]
        if medical_matches:
            medical_conditions = [f"title LIKE '%{kw}%'" for kw in medical_matches]
            conditions.append("(" + " OR ".join(medical_conditions) + ")")
        
        # é‡‡è´­æ„å‘ç­›é€‰
        if 'æ„å‘' in query_lower or 'é‡‡è´­æ„å‘' in query_lower:
            conditions.append("info_type LIKE '%æ„å‘%'")
        
        # 11æœˆæ—¶é—´ç­›é€‰
        if '11æœˆ' in query_lower or 'åä¸€æœˆ' in query_lower:
            conditions.append("EXTRACT(MONTH FROM publish_time) = 11")
            current_year = datetime.now().year
            conditions.append(f"EXTRACT(YEAR FROM publish_time) = {current_year}")
        
        # å…¶ä»–æ¡ä»¶
        if 'æ‹›æ ‡' in query_lower:
            conditions.append("info_type LIKE '%æ‹›æ ‡%'")
        elif 'ä¸­æ ‡' in query_lower:
            conditions.append("info_type LIKE '%ä¸­æ ‡%'")
        
        return conditions

    def add_ordering(self, base_sql, query_lower, target_table):
        """æ·»åŠ æ’åº"""
        if 'æœ€æ–°' in query_lower or 'æœ€è¿‘' in query_lower:
            base_sql += " ORDER BY publish_time DESC"
        elif 'é¢„ç®—' in query_lower and target_table == 'procurement_intention':
            base_sql += " ORDER BY intention_budget_amount DESC"
        else:
            base_sql += " ORDER BY publish_time DESC"
        
        return base_sql

    def analyze_query_results(self, original_query, query_results, target_tables):
        """åˆ†ææŸ¥è¯¢ç»“æœ"""
        if not query_results:
            return "æœªæ‰¾åˆ°åŒ¹é…çš„æ•°æ®"
        
        try:
            analysis_parts = []
            analysis_parts.append(f"å…±æ‰¾åˆ° {len(query_results)} æ¡ç›¸å…³è®°å½•")
            
            # æ—¶é—´åˆ†æ
            if query_results and 'publish_time' in query_results[0]:
                dates = [r['publish_time'] for r in query_results if r.get('publish_time')]
                if dates:
                    latest = max(dates)
                    oldest = min(dates)
                    analysis_parts.append(f"æ—¶é—´èŒƒå›´: {oldest} è‡³ {latest}")
            
            # åœ°åŒºåˆ†å¸ƒ
            if query_results and 'jurisdiction' in query_results[0]:
                jurisdictions = [r['jurisdiction'] for r in query_results if r.get('jurisdiction')]
                if jurisdictions:
                    jurisdiction_counts = Counter(jurisdictions)
                    top_areas = jurisdiction_counts.most_common(3)
                    area_info = ", ".join([f"{area}({count})" for area, count in top_areas])
                    analysis_parts.append(f"ä¸»è¦åœ°åŒº: {area_info}")
            
            # é¢„ç®—åˆ†æ
            if query_results and 'intention_budget_amount' in query_results[0]:
                budgets = [r['intention_budget_amount'] for r in query_results if r.get('intention_budget_amount')]
                if budgets:
                    valid_budgets = [b for b in budgets if b and b > 0]
                    if valid_budgets:
                        total_budget = sum(valid_budgets)
                        avg_budget = total_budget / len(valid_budgets)
                        analysis_parts.append(f"å¹³å‡é¢„ç®—: Â¥{avg_budget:,.2f}")
            
            return " | ".join(analysis_parts)
            
        except Exception as e:
            logger.error(f"ç»“æœåˆ†æå¤±è´¥: {e}")
            return "æ•°æ®åˆ†æå®Œæˆ"

    def format_data_analysis_response(self, original_query, sql_query, query_results, analysis, target_tables):
        """æ ¼å¼åŒ–æ•°æ®åˆ†æå“åº”"""
        # ç”ŸæˆHTMLæ ¼å¼çš„å“åº”
        html_response = self.generate_html_analysis(original_query, sql_query, query_results, analysis, target_tables)
        
        return {
            'status': 'success',
            'response_type': 'data_analysis',
            'message': html_response,
            'data_count': len(query_results),
            'sql_query': sql_query,
            'analysis_summary': analysis,
            'table_used': target_tables,
            'formatted': True
        }

    def generate_html_analysis(self, original_query, sql_query, query_results, analysis, target_tables):
        """ç”ŸæˆHTMLæ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        if not query_results:
            return f"""
            <div class="alert alert-warning">
                <h4>ğŸ” æŸ¥è¯¢ç»“æœ</h4>
                <p>æœªæ‰¾åˆ°åŒ¹é…çš„æ•°æ®ï¼Œè¯·å°è¯•è°ƒæ•´æœç´¢æ¡ä»¶ã€‚</p>
                <p><strong>åŸå§‹æŸ¥è¯¢:</strong> {original_query}</p>
            </div>
            """
        
        html_parts = []
        
        # å¤´éƒ¨ä¿¡æ¯
        html_parts.append(f"""
        <div class="data-analysis-result">
            <div class="analysis-header alert alert-success">
                <h4>ğŸ“Š æ•°æ®åˆ†æç»“æœ</h4>
                <p><strong>æŸ¥è¯¢:</strong> {original_query}</p>
                <p><strong>ç»“æœ:</strong> {analysis}</p>
                <p><strong>æ•°æ®è¡¨:</strong> {target_tables}</p>
            </div>
        """)
        
        # SQLæŸ¥è¯¢é¢„è§ˆ
        if sql_query:
            html_parts.append(f"""
            <div class="sql-preview mb-3">
                <details>
                    <summary class="btn btn-outline-secondary btn-sm">ğŸ” æŸ¥çœ‹SQLæŸ¥è¯¢</summary>
                    <pre class="mt-2 p-3 bg-light border rounded"><code>{sql_query}</code></pre>
                </details>
            </div>
            """)
        
        # æ•°æ®è¡¨æ ¼
        html_parts.append(self.generate_data_table_html(query_results))
        
        html_parts.append("</div>")
        return "".join(html_parts)

    def generate_data_table_html(self, data):
        """ç”Ÿæˆæ•°æ®è¡¨æ ¼HTML"""
        if not data:
            return '<div class="alert alert-warning">æš‚æ— æ•°æ®</div>'
        
        headers = list(data[0].keys())
        
        table_html = f"""
        <div class="table-responsive mt-3">
            <table class="table table-hover table-striped">
                <thead class="table-dark">
                    <tr>{"".join([f"<th>{self.format_header_name(h)}</th>" for h in headers])}</tr>
                </thead>
                <tbody>
        """
        
        for row in data[:1000]:
            table_html += "<tr>"
            for header in headers:
                value = row.get(header, '')
                table_html += f"<td>{self.format_cell_value(value, header)}</td>"
            table_html += "</tr>"
        
        table_html += """
                </tbody>
            </table>
        </div>
        """
        
        if len(data) > 1000:
            table_html += f'<div class="mt-2 text-muted">ä»…æ˜¾ç¤ºå‰1000æ¡è®°å½•ï¼Œå…±{len(data)}æ¡è®°å½•</div>'
        
        return table_html

    def format_header_name(self, header):
        """æ ¼å¼åŒ–è¡¨å¤´åç§°"""
        header_map = {
            'url': 'ğŸ”— é“¾æ¥',
            'title': 'ğŸ“ æ ‡é¢˜',
            'jurisdiction': 'ğŸ“ åœ°åŒº',
            'info_type': 'ğŸ“Š ç±»å‹',
            'publish_time': 'ğŸ“… æ—¶é—´',
            'intention_budget_amount': 'ğŸ’° é¢„ç®—',
            'intention_procurement_unit': 'ğŸ¢ é‡‡è´­å•ä½',
            'content_preview': 'ğŸ“„ å†…å®¹é¢„è§ˆ'
        }
        return header_map.get(header, header)

    def format_cell_value(self, value, header):
        """æ ¼å¼åŒ–å•å…ƒæ ¼å€¼"""
        if value is None or value == '':
            return '<span class="text-muted">-</span>'
        
        if header == 'url' and isinstance(value, str) and value.startswith('http'):
            return f'<a href="{value}" target="_blank" class="text-primary">æŸ¥çœ‹è¯¦æƒ…</a>'
        
        if header == 'intention_budget_amount' and value:
            if isinstance(value, (int, float)):
                return f'Â¥{value:,.2f}'
        
        if isinstance(value, str) and len(value) > 50:
            return f'<span title="{value}">{value[:50]}...</span>'
        
        return str(value)

    def get_database_context(self):
        """è·å–æ•°æ®åº“ä¸Šä¸‹æ–‡"""
        global database_understanding_cache
        if database_understanding_cache.get('schema_info'):
            return database_understanding_cache['schema_info']
        return None

    def execute_sql_query(self, sql_query):
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        try:
            with connection.cursor() as cursor:
                # å®‰å…¨æ£€æŸ¥ï¼šåªå…è®¸SELECTæŸ¥è¯¢
                sql_upper = sql_query.upper().strip()
                if not sql_upper.startswith('SELECT'):
                    logger.warning(f"éSELECTæŸ¥è¯¢è¢«æ‹’ç»: {sql_query}")
                    return None
                
                cursor.execute(sql_query)
                columns = [col[0] for col in cursor.description]
                rows = cursor.fetchall()
                
                result = []
                for row in rows:
                    row_dict = {}
                    for i, col in enumerate(columns):
                        value = row[i]
                        if value and columns[i] == 'content' and isinstance(value, str) and value.startswith('{'):
                            try:
                                row_dict[col] = json.loads(value)
                            except:
                                row_dict[col] = value
                        else:
                            row_dict[col] = value
                    result.append(row_dict)
                
                return result
        except Exception as e:
            logger.error(f"SQLæ‰§è¡Œå¤±è´¥: {e}")
            return None

    def handle_normal_chat(self, message):
        """å¤„ç†æ™®é€šèŠå¤©"""
        if self.ai_client:
            try:
                response = self.ai_client.chat.completions.create(
                    model=self.model_name,
                    messages=[{"role": "user", "content": message}],
                    max_tokens=500
                )
                return {
                    'status': 'success',
                    'response_type': 'normal_chat',
                    'message': response.choices[0].message.content
                }
            except Exception as e:
                logger.error(f"AIèŠå¤©å¤±è´¥: {e}")
        
        return {
            'status': 'success',
            'response_type': 'normal_chat', 
            'message': 'æ‚¨å¥½ï¼å¦‚éœ€æ•°æ®æŸ¥è¯¢ï¼Œè¯·åœ¨æ¶ˆæ¯ä¸­æ·»åŠ  #psql æ ‡ç­¾ã€‚'
        }

    def clean_psql_marker(self, message):
        """æ¸…ç†æ¶ˆæ¯ä¸­çš„psqlæ ‡è®°"""
        markers = ['#psql', '#p s q l', '#PSQL', '#P S Q L']
        cleaned = message
        for marker in markers:
            cleaned = cleaned.replace(marker, '')
        return cleaned.strip()

    def ensure_response_format(self, response_data):
        """ç¡®ä¿å“åº”æ ¼å¼ç»Ÿä¸€"""
        if isinstance(response_data, JsonResponse):
            return response_data
        
        if isinstance(response_data, dict):
            if 'status' not in response_data:
                response_data['status'] = 'success'
            if 'timestamp' not in response_data:
                response_data['timestamp'] = datetime.now().isoformat()
            
            return JsonResponse(response_data)
        else:
            return self.error_response("æœåŠ¡å™¨è¿”å›äº†æœªçŸ¥çš„å“åº”æ ¼å¼")

    def error_response_dict(self, error_message):
        """è¿”å›é”™è¯¯å“åº”çš„å­—å…¸æ ¼å¼"""
        return {
            'status': 'error',
            'message': error_message
        }

    def error_response(self, error_message):
        """è¿”å›é”™è¯¯å“åº”çš„JsonResponseæ ¼å¼"""
        return JsonResponse({
            'status': 'error',
            'message': error_message,
            'timestamp': datetime.now().isoformat()
        })

# åˆ›å»ºå…¨å±€å¤„ç†å™¨å®ä¾‹
chat_processor = ChatMessageProcessor()

@csrf_exempt
@require_http_methods(["GET", "POST"])
def chat(request):
    """ç»Ÿä¸€çš„chatè§†å›¾"""
    
    if request.method == 'GET':
        return render(request, 'tool/chat.html')
    
    elif request.method == 'POST':
        try:
            if request.content_type == 'application/json':
                data = json.loads(request.body)
            else:
                data = request.POST
            
            if 'session_id' not in data:
                data['session_id'] = 'default'
            
            return chat_processor.process_message(data)
            
        except json.JSONDecodeError:
            return JsonResponse({
                'status': 'error', 
                'message': 'æ•°æ®æ ¼å¼é”™è¯¯'
            }, status=400)
        except Exception as e:
            logger.error(f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {e}")
            return JsonResponse({
                'status': 'error', 
                'message': f'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}'
            }, status=500)
